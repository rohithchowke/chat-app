{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import os\n",
    "import PyPDF2\n",
    "import chromadb\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load ENV\n",
    "ENV_DIR = Path().absolute().parent / \".env\"\n",
    "DEV_ENV_FILE_PATH = ENV_DIR / \"dev.env\"\n",
    "load_dotenv(DEV_ENV_FILE_PATH, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Azure OpenAI client\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT_SLN\"],\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY_SLN\"],\n",
    "    api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    ")\n",
    "\n",
    "# Function to read PDF\n",
    "def read_pdf(uploadedfile):\n",
    "    pdf_text = \"\"\n",
    "    pdfReader = PyPDF2.PdfReader(uploadedfile)\n",
    "    for page_num in range(len(pdfReader.pages)):\n",
    "        page = pdfReader.pages[page_num]\n",
    "        pdf_text += page.extract_text()\n",
    "    return pdf_text\n",
    "\n",
    "# Cache the embeddings generation\n",
    "@st.cache_resource\n",
    "def generate_embeddings(texts):\n",
    "    response = client.embeddings.create(\n",
    "        model=os.environ[\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME_ADA_SLN\"],\n",
    "        input=[texts]\n",
    "    )\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ChromaDB client and collection\n",
    "chroma_client = chromadb.Client()\n",
    "collection = chroma_client.get_or_create_collection(name=\"all-my-document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split text into smaller chunks for embeddings\n",
    "def split_text_into_chunks(text, max_chunk_size=512):\n",
    "    sentences = text.split('. ')\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    current_length = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_length = len(sentence.split())\n",
    "        if current_length + sentence_length <= max_chunk_size:\n",
    "            current_chunk += (sentence + '. ')\n",
    "            current_length += sentence_length\n",
    "        else:\n",
    "            chunks.append(current_chunk.strip())\n",
    "            current_chunk = sentence + '. '\n",
    "            current_length = sentence_length\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Cache all document data\n",
    "@st.cache_resource\n",
    "def cache_documents(uploaded_file, department):\n",
    "    collection_data = st.session_state.get(\"collection_data\", {})\n",
    "    document_content = read_pdf(uploaded_file)\n",
    "    if document_content:\n",
    "        clean_text = document_content.replace('\\n', ' ').strip()\n",
    "        texts = split_text_into_chunks(clean_text)\n",
    "        metadatas = [{\"chunk_index\": i, \"department\": department} for i in range(len(texts))]\n",
    "        document_uuid = str(uuid.uuid4())\n",
    "        ids = [f\"doc_{i}_{document_uuid}\" for i in range(len(texts))]\n",
    "        embeds = [generate_embeddings(text) for text in texts]\n",
    "\n",
    "        collection_data.update({\n",
    "            document_uuid: {\n",
    "                \"texts\": texts,\n",
    "                \"metadatas\": metadatas,\n",
    "                \"ids\": ids,\n",
    "                \"embeddings\": embeds,\n",
    "            }\n",
    "        })\n",
    "\n",
    "        st.session_state[\"collection_data\"] = collection_data\n",
    "        st.sidebar.write(\"Documents cached successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cached_data_to_chromadb():\n",
    "    collection_data = st.session_state.get(\"collection_data\", {})\n",
    "    for cached_document in collection_data.values():\n",
    "        collection.upsert(\n",
    "            documents=cached_document[\"texts\"],\n",
    "            metadatas=cached_document[\"metadatas\"],\n",
    "            ids=cached_document[\"ids\"],\n",
    "            embeddings=cached_document[\"embeddings\"],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-28 11:09:24.305 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "@st.cache_data\n",
    "def fetch_documents_by_department(department):\n",
    "    all_docs = collection.get(include=[\"documents\", \"metadatas\"])\n",
    "    filtered_docs = [\" \".join(doc) for i, doc in enumerate(all_docs['documents']) if all_docs['metadatas'][i]['department'] == department]\n",
    "    return \" \".join(filtered_docs) if filtered_docs else \"\"\n",
    "\n",
    "def is_summarization(query):\n",
    "    summarize_keywords = ['summarize', 'summary', 'summarise', 'overview', 'about the document', 'details of the document']\n",
    "    return any(keyword in query.lower() for keyword in summarize_keywords)\n",
    "\n",
    "def chat_with_ai(query, department):\n",
    "    context = fetch_documents_by_department(department)\n",
    "    user_embedding = generate_embeddings(query)\n",
    "    results = collection.query(\n",
    "        query_embeddings=[user_embedding],\n",
    "        n_results=3,  # Fetch top 3 results\n",
    "        include=[\"documents\", \"distances\"]\n",
    "    )\n",
    "\n",
    "    if results and 'documents' in results and 'distances' in results:\n",
    "        # Flatten results and calculate cosine similarity\n",
    "        context_documents = [doc for sublist in results['documents'] for doc in sublist]\n",
    "        distances = [dist for sublist in results['distances'] for dist in sublist]\n",
    "        context = context_documents[0]  # Use the top result initially\n",
    "\n",
    "        # If additional context from other documents is beneficial, include them based on distance\n",
    "        for i in range(1, len(context_documents)):\n",
    "            similarity_score = cosine_similarity([user_embedding], [generate_embeddings(context_documents[i])])[0][0]\n",
    "            if similarity_score > 0.7:  # Adjusting the threshold\n",
    "                context += \" \" + context_documents[i]\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant. Answer strictly based on the content provided. Understand the query properly and answer accordingly.\"},\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "            {\"role\": \"assistant\", \"content\": f\"Relevant context from document:\\n\\n{context}\"},\n",
    "        ]\n",
    "    else:\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant. Answer strictly based on the known content. If you do not know the answer for sure, indicate your uncertainty politely rather than stating 'I don't know.'.\"},\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "            {\"role\": \"assistant\", \"content\": \"No relevant context was found directly from the documents. However, I'm here to help. Please clarify your question or provide more details.\"},\n",
    "        ]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME_SLN\"],\n",
    "            messages=messages,\n",
    "            temperature=0.7,\n",
    "            max_tokens=1000,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "        )\n",
    "        response_content = response.choices[0].message.content\n",
    "        return response_content\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    st.set_page_config(page_title=\"Azure OpenAI Chat\", layout=\"wide\")\n",
    "    st.title(\"Azure OpenAI Chat with Document Context\")\n",
    "\n",
    "    st.sidebar.header(\"Upload PDF Document\")\n",
    "    department = st.sidebar.text_input(\"Enter the department\")\n",
    "\n",
    "    if st.sidebar.button(\"Confirm Department\"):\n",
    "        st.session_state[\"department\"] = department\n",
    "        st.sidebar.success(f\"Department set to: {department}\")\n",
    "\n",
    "    uploaded_file = st.sidebar.file_uploader(\"Choose a PDF file\", type=[\"pdf\"])\n",
    "\n",
    "    if uploaded_file is not None:\n",
    "        if \"department\" in st.session_state and st.session_state[\"department\"]:\n",
    "            cache_documents(uploaded_file, st.session_state[\"department\"])\n",
    "            add_cached_data_to_chromadb()\n",
    "        else:\n",
    "            st.sidebar.error(\"Please confirm the department before uploading the file.\")\n",
    "\n",
    "    st.header(\"Chat with AI\")\n",
    "    query = st.text_input(\"Enter your query:\")\n",
    "\n",
    "    if st.button(\"Submit\"):\n",
    "        if query:\n",
    "            if \"department\" in st.session_state and st.session_state[\"department\"]:\n",
    "                response = chat_with_ai(query, st.session_state[\"department\"])\n",
    "                st.write(\"Response from AI:\")\n",
    "                st.write(response)\n",
    "            else:\n",
    "                st.error(\"Please confirm the department before submitting a query.\")\n",
    "        else:\n",
    "            st.error(\"Please enter a query.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-28 11:09:55.961 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 11:09:55.961 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 11:09:57.332 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\ROHITCH1\\OneDrive - Novartis Pharma AG\\Desktop\\VanillaApp\\venv\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-02-28 11:09:57.339 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 11:09:57.340 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 11:09:57.340 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 11:09:57.340 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 11:09:57.340 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 11:09:57.340 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 11:09:57.340 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 11:09:57.340 Session state does not function when running a script without `streamlit run`\n",
      "2025-02-28 11:09:57.340 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 11:09:57.340 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 11:09:57.340 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 11:09:57.340 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 11:09:57.340 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 11:09:57.340 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 11:09:57.340 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 11:09:57.340 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 11:09:57.349 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 11:09:57.349 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 11:09:57.349 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 11:09:57.349 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 11:09:57.349 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 11:09:57.349 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 11:09:57.349 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 11:09:57.354 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 11:09:57.356 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 11:09:57.357 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 11:09:57.358 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 11:09:57.359 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 11:09:57.359 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 11:09:57.360 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 11:09:57.360 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 11:09:57.361 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 11:09:57.362 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
